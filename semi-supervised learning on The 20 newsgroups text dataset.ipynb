{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e5dfb0",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5ea442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.semi_supervised import LabelSpreading , LabelPropagation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from simcse import SimCSE\n",
    "import re\n",
    "import string\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d60b5c",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3bf413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823 documents\n",
      "5 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset containing first five categories\n",
    "data = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=[\n",
    "        \"alt.atheism\",\n",
    "        \"comp.graphics\",\n",
    "        \"comp.os.ms-windows.misc\",\n",
    "        \"comp.sys.ibm.pc.hardware\",\n",
    "        \"comp.sys.mac.hardware\",\n",
    "    ],\n",
    ")\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ee0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573c9b7",
   "metadata": {},
   "source": [
    "## Pre-processing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4202a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing emails from the text\n",
    "def remove_emails(text):\n",
    "    text = re.sub('\\S*@\\S*\\s?', '', text)\n",
    "    return text\n",
    "\n",
    "# remove duplicate spaces and new lines\n",
    "def remove_spaces(text):\n",
    "    text = [\" \".join(re.split(\"\\s+\", word, flags=re.UNICODE)) for word in text]\n",
    "    return text\n",
    "\n",
    "# removing punctuations\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "    \n",
    "# tokenization\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "# removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "# texting Lemmitization\n",
    "def lemmatizer(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cb3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # convert the text to lowercase\n",
    "    text_lower = text.lower() \n",
    "    \n",
    "    # removing emails from the text\n",
    "    text_without_emails = remove_emails(text_lower)\n",
    "    \n",
    "    # remove duplicate spaces and new lines\n",
    "    text_without_spaces = remove_spaces(text_without_emails)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text_without_punctuations = remove_punct(text_without_spaces)\n",
    "    \n",
    "    # text tokenization\n",
    "    tokens = tokenization(text_without_punctuations)   \n",
    "    \n",
    "    # removing stopwords \n",
    "    text_without_stopwords = remove_stopwords(tokens)\n",
    "    \n",
    "    # text Lemmitization\n",
    "    text_clean = lemmatizer(text_without_stopwords)\n",
    "    \n",
    "    return \" \".join(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e8c4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brian v hughes subject new apple ergomouse replyto organization dartmouth college hanover nh disclaimer personally really dont care think speak moderator recartscomicsinfo line schizophrenia mean never alone writes anyone know open apple ergomouse adb mouse ii mine life near cat true really pick fur tell look like apple welded shut must tried hard opend mine second take look bottom dial turn open much like older adb mouse used bit harder turn first quite simple open also anyone know installing fpus mac lc iii ive heard people saying fried motherboard lc iii well dont match pin correctly problem close look socket give idea proper orientation chip hades '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [clean_text(x) for x in X]\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd264bfa",
   "metadata": {},
   "source": [
    "## Creating the embeddings model and transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfab00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrhman/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      " 71%|██████████████████████████████▌            | 32/45 [03:46<01:36,  7.46s/it]"
     ]
    }
   ],
   "source": [
    "# loading SimCSE embeddings model\n",
    "embeddings_model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n",
    "\n",
    "def encoding_with_embeddings(model,data):\n",
    "    embeddings = model.encode(data)\n",
    "    return embeddings\n",
    "X = encoding_with_embeddings(embeddings_model,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e05df",
   "metadata": {},
   "source": [
    "## creating the machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c017d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Propagation Model\n",
    "lp_model = LabelPropagation()\n",
    "\n",
    "# Label Spreading Model\n",
    "ls_model = LabelSpreading()\n",
    "\n",
    "# function for training and evaluating each model\n",
    "def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"Number of training samples:\", len(X_train))\n",
    "    print(\"Unlabeled samples in training set:\", sum(1 for x in y_train if x == -1))\n",
    "    \n",
    "    # training the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # making predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\n",
    "        \"accuracy score on test set: %0.3f\"\n",
    "        % accuracy_score(y_test, y_pred)\n",
    "    )\n",
    "    print(\"-\" * 10)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f11118",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08805fc",
   "metadata": {},
   "source": [
    "### Spliting into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306cbaa3",
   "metadata": {},
   "source": [
    "### Creating unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a mask of 20% of the train dataset\n",
    "mask_percentage = 0.2\n",
    "y_mask = np.random.rand(len(y_train)) < mask_percentage\n",
    "\n",
    "\n",
    "# set the non-masked subset to be unlabeled\n",
    "y_train[~y_mask] = -1\n",
    "\n",
    "print(f\"LabelSpreading on {mask_percentage*100}% of the data (rest is unlabeled):\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35882588",
   "metadata": {},
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603267fe",
   "metadata": {},
   "source": [
    "### Label Propagation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444de081",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_and_print_metrics(lp_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a4631",
   "metadata": {},
   "source": [
    "### Label Spreading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_and_print_metrics(ls_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4f0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
